{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, I will using Alternating Least Squares (ALS) algorithm to predict the ratings for movies in data set [MoviesLensSmall](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL 3515\\AppData\\Local\\Temp\\ipykernel_9660\\177025693.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\College\\\\WRK\\\\Machine_learning'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "os.chdir('D:\\College\\WRK\\Machine_learning')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"movies recommendation\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = spark.read.load(\"data/ml-latest-small/movies.csv\", format='csv', header = True)\n",
    "ratings = spark.read.load(\"data/ml-latest-small/ratings.csv\", format='csv', header = True)\n",
    "links = spark.read.load(\"data/ml-latest-small/links.csv\", format='csv', header = True)\n",
    "tags = spark.read.load(\"data/ml-latest-small/tags.csv\", format='csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.createOrReplaceTempView(\"movies\")\n",
    "\n",
    "limit5 = spark.sql(\"SELECT * FROM movies limit 5\")\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "\n",
    "limit5 = spark.sql(\"SELECT * FROM ratings limit 5\")\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------------+----------+\n",
      "|userId|movieId|            tag| timestamp|\n",
      "+------+-------+---------------+----------+\n",
      "|     2|  60756|          funny|1445714994|\n",
      "|     2|  60756|Highly quotable|1445714996|\n",
      "|     2|  60756|   will ferrell|1445714992|\n",
      "|     2|  89774|   Boxing story|1445715207|\n",
      "|     2|  89774|            MMA|1445715200|\n",
      "+------+-------+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags.createOrReplaceTempView(\"tags\")\n",
    "\n",
    "limit5 = spark.sql(\"SELECT * FROM tags limit 5\")\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|movieId| imdbId|tmdbId|\n",
      "+-------+-------+------+\n",
      "|      1|0114709|   862|\n",
      "|      2|0113497|  8844|\n",
      "|      3|0113228| 15602|\n",
      "|      4|0114885| 31357|\n",
      "|      5|0113041| 11862|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "links.createOrReplaceTempView(\"links\")\n",
    "\n",
    "limit5 = spark.sql(\"SELECT * FROM links limit 5\")\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the users that rated movies and the movies that were rated:\n",
      "Minimum number of ratings per user is 20\n",
      "Minimum number of ratings per movie is 1\n"
     ]
    }
   ],
   "source": [
    "count_min_rating_per_user = ratings.groupBy(\"userID\").count().toPandas()['count'].min()\n",
    "count_min_rating_per_movie = ratings.groupBy(\"movieId\").count().toPandas()['count'].min()\n",
    "\n",
    "print('For the users that rated movies and the movies that were rated:')\n",
    "print('Minimum number of ratings per user is {}'.format(count_min_rating_per_user))\n",
    "print('Minimum number of ratings per movie is {}'.format(count_min_rating_per_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3446 out of 9724 movies are rated by only one user equal 35.44 %\n"
     ]
    }
   ],
   "source": [
    "tmp1 = sum(ratings.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n",
    "tmp2 = ratings.select('movieId').distinct().count()\n",
    "\n",
    "print('{} out of {} movies are rated by only one user equal {:.2f} %'.format(tmp1, tmp2,tmp1 * 100 /tmp2*1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|num_users|\n",
      "+---------+\n",
      "|      610|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_users = spark.sql(\"SELECT count (distinct userID) as num_users FROM ratings\")\n",
    "num_users.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.select(\"userId\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|num_movies|\n",
      "+----------+\n",
      "|      9742|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sql\n",
    "num_movies = spark.sql(\"SELECT count (distinct movieID) as num_movies FROM movies\")\n",
    "num_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.select('movieID').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many Movies was rated by Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many movies are rated by users? \n",
      " 9724\n"
     ]
    }
   ],
   "source": [
    "rated_by_users = ratings.select('movieID').distinct().count()\n",
    "print('How many movies are rated by users? \\n', rated_by_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many Movies genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|       movies_genres|\n",
      "+--------------------+\n",
      "|Comedy|Horror|Thr...|\n",
      "|Adventure|Sci-Fi|...|\n",
      "|Action|Adventure|...|\n",
      "| Action|Drama|Horror|\n",
      "|Action|Animation|...|\n",
      "|Animation|Childre...|\n",
      "|Action|Adventure|...|\n",
      "|    Adventure|Sci-Fi|\n",
      "|Documentary|Music...|\n",
      "|Adventure|Childre...|\n",
      "| Adventure|Animation|\n",
      "| Musical|Romance|War|\n",
      "|Action|Adventure|...|\n",
      "|Adventure|Childre...|\n",
      "|Comedy|Crime|Horr...|\n",
      "|Crime|Drama|Fanta...|\n",
      "|Comedy|Mystery|Th...|\n",
      "|   Adventure|Fantasy|\n",
      "|Horror|Romance|Sc...|\n",
      "|Drama|Film-Noir|R...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mv_genres = spark.sql(\"SELECT DISTINCT(genres) as movies_genres FROM movies \")\n",
    "mv_genres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|             genre|\n",
      "+------------------+\n",
      "|(no genres listed)|\n",
      "|            Action|\n",
      "|         Adventure|\n",
      "|         Animation|\n",
      "|          Children|\n",
      "|            Comedy|\n",
      "|             Crime|\n",
      "|       Documentary|\n",
      "|             Drama|\n",
      "|           Fantasy|\n",
      "|         Film-Noir|\n",
      "|            Horror|\n",
      "|              IMAX|\n",
      "|           Musical|\n",
      "|           Mystery|\n",
      "|           Romance|\n",
      "|            Sci-Fi|\n",
      "|          Thriller|\n",
      "|               War|\n",
      "|           Western|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specific Genres\n",
    "\n",
    "genres = spark.sql(\"\"\"\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 1), '|', -1) as genre FROM movies\n",
    "    UNION\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 2), '|', -1) as genre FROM movies\n",
    "    UNION\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 3), '|', -1) as genre FROM movies\n",
    "    UNION\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 4), '|', -1) as genre FROM movies\n",
    "    UNION\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 5), '|', -1) as genre FROM movies\n",
    "    UNION\n",
    "    SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 6), '|', -1) as genre FROM movies\n",
    "    ORDER BY genre\n",
    "\"\"\")\n",
    "\n",
    "genres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(no genres listed)</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
       "0                   0       0          1          1         1       1      0   \n",
       "1                   0       0          1          0         1       0      0   \n",
       "2                   0       0          0          0         0       1      0   \n",
       "3                   0       0          0          0         0       1      0   \n",
       "4                   0       0          0          0         0       1      0   \n",
       "\n",
       "   Documentary  Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  \\\n",
       "0            0      0        1          0       0     0        0        0   \n",
       "1            0      0        1          0       0     0        0        0   \n",
       "2            0      0        0          0       0     0        0        0   \n",
       "3            0      1        0          0       0     0        0        0   \n",
       "4            0      0        0          0       0     0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         0    0        0  \n",
       "2        1       0         0    0        0  \n",
       "3        1       0         0    0        0  \n",
       "4        0       0         0    0        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_pdf = movies.toPandas()\n",
    "movie_pdf['genres'].str.get_dummies(sep='|').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_movie = list(movie_pdf['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark ALS based approach for training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an Spark ML to predict the ratings, so let's reload \"ratings.csv\" using sc.textFile and then convert it to the form of (user, item, rating) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "+------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limit5 = spark.sql(\"SELECT * FROM ratings limit 5\")\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings=ratings.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n",
    "movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.createOrReplaceTempView(\"movie_ratings\")\n",
    "\n",
    "limit10 =  (spark.sql(\"SELECT * FROM movie_ratings limit 10\"))\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS Model Selection and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ALS model, we can use a grid search to find the optimal hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test and train set\n",
    "(training,test)=movie_ratings.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ALS model\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: alpha for implicit preference (default: 1.0)\n",
      "blockSize: block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data. (default: 4096)\n",
      "checkpointInterval: set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext. (default: 10)\n",
      "coldStartStrategy: strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'. (default: nan, current: drop)\n",
      "finalStorageLevel: StorageLevel for ALS model factors. (default: MEMORY_AND_DISK)\n",
      "implicitPrefs: whether to use implicit preference (default: False)\n",
      "intermediateStorageLevel: StorageLevel for intermediate datasets. Cannot be 'NONE'. (default: MEMORY_AND_DISK)\n",
      "itemCol: column name for item ids. Ids must be within the integer value range. (default: item, current: movieId)\n",
      "maxIter: max number of iterations (>= 0). (default: 10, current: 5)\n",
      "nonnegative: whether to use nonnegative constraint for least squares (default: False)\n",
      "numItemBlocks: number of item blocks (default: 10)\n",
      "numUserBlocks: number of user blocks (default: 10)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "rank: rank of the factorization (default: 10, current: 10)\n",
      "ratingCol: column name for ratings (default: rating, current: rating)\n",
      "regParam: regularization parameter (>= 0). (default: 0.1, current: 0.01)\n",
      "seed: random seed. (default: -1446461554123018518)\n",
      "userCol: column name for user ids. Ids must be within the integer value range. (default: user, current: userId)\n"
     ]
    }
   ],
   "source": [
    "# 1st print a list of parameters\n",
    "print(als.explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune model using ParamGridBuilder\n",
    "# it will take long time in the cv period, so just use few parameter to try \n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(als.regParam, [0.01])\n",
    "             .addGrid(als.rank, [10])\n",
    "             .addGrid(als.maxIter, [15])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator as RMSE\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "# Build Cross validation \n",
    "# Create 5-fold CrossValidator\n",
    "# it takes too long that I only use 2-fold\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(training)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the best model selected by CV\n",
    "best_model = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model\n",
      "Rank:  ALSModel: uid=ALS_9c3d3a70c09f, rank=10\n",
      "MaxIter:  15\n",
      "RegParam: ALS_9c3d3a70c09f__regParam\n"
     ]
    }
   ],
   "source": [
    "#Fit ALS model to training data\n",
    "\n",
    "# specify parameter settings by the best model obtained via CV\n",
    "print (\"Best Model\")\n",
    "print (\"Rank: \", best_model)\n",
    "print (\"MaxIter: \", str(best_model._java_obj.parent().getMaxIter()))\n",
    "print (\"RegParam:\",  best_model._java_obj.parent().regParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions and evaluate using RMSE\n",
    "predictions=best_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 1.1456151134572492\n"
     ]
    }
   ],
   "source": [
    "#Print RMSE \n",
    "print (\"RMSE = {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract best model from the tuning exercise using ParamGridBuilder\n",
    "als_best = ALS(maxIter=15, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als_best.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   463|   1088|   3.5| 1.9607128|\n",
      "|   133|    471|   4.0|  3.749315|\n",
      "|   597|   1959|   4.0| 4.6991343|\n",
      "|   108|   1959|   5.0| 4.5030694|\n",
      "|   368|   1645|   3.0| 2.8509874|\n",
      "|   101|   3175|   4.0| 3.1413093|\n",
      "|   115|   1645|   4.0|   3.00947|\n",
      "|   385|    471|   4.0| 3.1198914|\n",
      "|   436|    471|   3.0| 4.8210683|\n",
      "|   587|   3175|   5.0| 3.8690786|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predictions.show(10)\n",
    "\n",
    "predictions.createOrReplaceTempView(\"predictions\")\n",
    "\n",
    "limit10 =  (spark.sql(\"SELECT * FROM predictions limit 10\"))\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model apply and see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.6506614529461175\n"
     ]
    }
   ],
   "source": [
    "alldata=best_model.transform(movie_ratings)\n",
    "rmse = evaluator.evaluate(alldata)\n",
    "print (\"RMSE = \"+str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\WRK\\Machine_learning\\venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "alldata.registerTempTable(\"alldata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   463|   1088|   3.5| 1.9607128|\n",
      "|   137|   1580|   3.5|  3.208893|\n",
      "|   580|   1580|   4.0| 3.3586917|\n",
      "|   580|   3175|   2.5| 3.4234302|\n",
      "|   580|  44022|   3.5| 3.9047294|\n",
      "|   133|    471|   4.0|  3.749315|\n",
      "|   322|   1580|   3.5| 3.1298318|\n",
      "|   362|   1591|   4.0| 3.2896817|\n",
      "|   362|   1645|   5.0| 3.8134174|\n",
      "|   593|   1580|   1.5| 2.4678888|\n",
      "+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limit10 = spark.sql('SELECT * FROM alldata LIMIT 10')\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "|movieId|               title|              genres|userId|movieId|rating|prediction|\n",
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "|   1088|Dirty Dancing (1987)|Drama|Musical|Rom...|   463|   1088|   3.5| 1.9607128|\n",
      "|   1580|Men in Black (a.k...|Action|Comedy|Sci-Fi|   137|   1580|   3.5|  3.208893|\n",
      "|   1580|Men in Black (a.k...|Action|Comedy|Sci-Fi|   580|   1580|   4.0| 3.3586917|\n",
      "|   3175| Galaxy Quest (1999)|Adventure|Comedy|...|   580|   3175|   2.5| 3.4234302|\n",
      "|  44022|Ice Age 2: The Me...|Adventure|Animati...|   580|  44022|   3.5| 3.9047294|\n",
      "|    471|Hudsucker Proxy, ...|              Comedy|   133|    471|   4.0|  3.749315|\n",
      "|   1580|Men in Black (a.k...|Action|Comedy|Sci-Fi|   322|   1580|   3.5| 3.1298318|\n",
      "|   1591|        Spawn (1997)|Action|Adventure|...|   362|   1591|   4.0| 3.2896817|\n",
      "|   1645|The Devil's Advoc...|Drama|Mystery|Thr...|   362|   1645|   5.0| 3.8134174|\n",
      "|   1580|Men in Black (a.k...|Action|Comedy|Sci-Fi|   593|   1580|   1.5| 2.4678888|\n",
      "+-------+--------------------+--------------------+------+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "limit10 = spark.sql('SELECT * FROM movies JOIN alldata ON movies.movieId=alldata.movieId LIMIT 10')\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommend 10 movies for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{94677, 7.363879...|\n",
      "|     2|[{1963, 6.7120776...|\n",
      "|     3|[{1211, 6.4078684...|\n",
      "|     4|[{1866, 9.520394}...|\n",
      "|     5|[{1866, 8.929421}...|\n",
      "|     6|[{674, 7.8965893}...|\n",
      "|     7|[{89753, 8.85826}...|\n",
      "|     8|[{3521, 7.6060257...|\n",
      "|     9|[{158872, 6.96302...|\n",
      "|    10|[{87485, 8.45906}...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#recommend 10 movies for each users\n",
    "user_recs = best_model.recommendForAllUsers(10)\n",
    "#user_recs.show(10)\n",
    "user_recs.createOrReplaceTempView(\"user_recs\")\n",
    "\n",
    "limit10 = (spark.sql(\"SELECT * FROM user_recs limit 10\"))\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user 1 recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(userId=1, recommendations=[Row(movieId=94677, rating=7.363879680633545), Row(movieId=3022, rating=6.843271255493164), Row(movieId=4799, rating=6.754696369171143), Row(movieId=26133, rating=6.685563564300537), Row(movieId=97304, rating=6.603682041168213), Row(movieId=91094, rating=6.540321350097656), Row(movieId=1194, rating=6.505104064941406), Row(movieId=4039, rating=6.501293182373047), Row(movieId=116897, rating=6.468926906585693), Row(movieId=79428, rating=6.466922283172607)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recs.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\WRK\\Machine_learning\\venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "user_recs.registerTempTable(\"als_recs_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|userId|          MovieRec|\n",
      "+------+------------------+\n",
      "|     1|{94677, 7.3638797}|\n",
      "|     1| {3022, 6.8432713}|\n",
      "|     1| {4799, 6.7546964}|\n",
      "|     1|{26133, 6.6855636}|\n",
      "|     1| {97304, 6.603682}|\n",
      "|     1|{91094, 6.5403214}|\n",
      "|     1|  {1194, 6.505104}|\n",
      "|     1|  {4039, 6.501293}|\n",
      "|     1|{116897, 6.468927}|\n",
      "|     1|{79428, 6.4669223}|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# seperate the value of 'recommendations' in user_recs\n",
    "\n",
    "explode_rec = spark.sql('SELECT userId,\\\n",
    "                                explode(recommendations) AS MovieRec\\\n",
    "                                FROM als_recs_temp')\n",
    "#explode_rec.show(10)\n",
    "\n",
    "\n",
    "explode_rec.createOrReplaceTempView(\"explode_rec\")\n",
    "\n",
    "limit10 = (spark.sql(\"SELECT * FROM explode_rec limit 10\"))\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recs = spark.sql(\"SELECT userId,\\\n",
    "                               movieIds_and_ratings.movieId AS movieId,\\\n",
    "                               movieIds_and_ratings.rating AS prediction\\\n",
    "                               FROM als_recs_temp\\\n",
    "                               LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|userId|movieId|prediction|\n",
      "+------+-------+----------+\n",
      "|     1|  94677| 7.3638797|\n",
      "|     1|   3022| 6.8432713|\n",
      "|     1|   4799| 6.7546964|\n",
      "|     1|  26133| 6.6855636|\n",
      "|     1|  97304|  6.603682|\n",
      "|     1|  91094| 6.5403214|\n",
      "|     1|   1194|  6.505104|\n",
      "|     1|   4039|  6.501293|\n",
      "|     1| 116897|  6.468927|\n",
      "|     1|  79428| 6.4669223|\n",
      "+------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_recs.createOrReplaceTempView(\"fianl_recs\")\n",
    "\n",
    "limit10= (spark.sql(\"SELECT * FROM fianl_recs limit 10\"))\n",
    "limit10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+------+\n",
      "|userId|movieId|prediction|rating|\n",
      "+------+-------+----------+------+\n",
      "|     1|  94677| 7.3638797|  NULL|\n",
      "|     1|   3022| 6.8432713|  NULL|\n",
      "|     1|   4799| 6.7546964|  NULL|\n",
      "|     1|  26133| 6.6855636|  NULL|\n",
      "|     1|  97304|  6.603682|  NULL|\n",
      "+------+-------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Before we recommend the films, we need to filter out those users have not seen yet. Therefore, we need to choose rating = 'null' by join the movie ratings\n",
    "\n",
    "final_rec = final_recs.join(movie_ratings,['userId','movieId'],'left').filter(movie_ratings.rating.isNull())\n",
    "\n",
    "final_rec.createOrReplaceTempView(\"final_rec\")\n",
    "\n",
    "limit5 = (spark.sql(\"SELECT * FROM final_rec LIMIT 5\"))\n",
    "limit5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\College\\WRK\\Machine_learning\\venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "final_rec.registerTempTable(\"final_rec\")\n",
    "movies.registerTempTable(\"movies_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Find recommend films for userid = 003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_for_003 = spark.sql(\"\"\"SELECT userId,\n",
    "                                    title\n",
    "                            FROM final_rec t1\n",
    "                            LEFT JOIN movies_df t2\n",
    "                                ON t1.movieId = t2.movieId\n",
    "                            WHERE t1.userId=003\n",
    "                            LIMIT 10\n",
    "                         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|               title|\n",
      "+------+--------------------+\n",
      "|     3|Wings of Desire (...|\n",
      "|     3|Hard-Boiled (Lat ...|\n",
      "|     3|     Scrooged (1988)|\n",
      "|     3|Cold Comfort Farm...|\n",
      "|     3|      Lockout (2012)|\n",
      "|     3|Killer, The (Die ...|\n",
      "|     3|Ninja Scroll (JÃ»b...|\n",
      "|     3|    Barb Wire (1996)|\n",
      "|     3|         Dune (2000)|\n",
      "|     3|How the Grinch St...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recs_for_003.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
